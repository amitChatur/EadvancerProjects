{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12230576,"sourceType":"datasetVersion","datasetId":7706107}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"e281dce6","cell_type":"code","source":"import pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport numpy as np\nimport os\n\nnltk.download('punkt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T08:27:32.396006Z","iopub.execute_input":"2025-06-23T08:27:32.396771Z","iopub.status.idle":"2025-06-23T08:27:32.403304Z","shell.execute_reply.started":"2025-06-23T08:27:32.396747Z","shell.execute_reply":"2025-06-23T08:27:32.402630Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":14},{"id":"c7419c11-5088-424f-ac69-fe8d5d18faa3","cell_type":"code","source":"pd.set_option('display.max_colwidth', None) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T09:30:28.748573Z","iopub.execute_input":"2025-06-23T09:30:28.749111Z","iopub.status.idle":"2025-06-23T09:30:28.752284Z","shell.execute_reply.started":"2025-06-23T09:30:28.749091Z","shell.execute_reply":"2025-06-23T09:30:28.751517Z"}},"outputs":[],"execution_count":37},{"id":"bffcc000-7e12-40b4-909f-0a4042efd3e3","cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T08:27:32.404479Z","iopub.execute_input":"2025-06-23T08:27:32.404781Z","iopub.status.idle":"2025-06-23T08:27:32.415668Z","shell.execute_reply.started":"2025-06-23T08:27:32.404756Z","shell.execute_reply":"2025-06-23T08:27:32.415001Z"}},"outputs":[],"execution_count":15},{"id":"a6099f1f-fcc7-4be2-bc79-4edd298b812a","cell_type":"markdown","source":"**Notes:**\n\n* Downloaded the Glove pre-embeddings of 100 dimensions from https://nlp.stanford.edu/data/glove.6B.zip\n* Convert the given input tokens according to downloaded Glove 100D representation\n* As it is sequential data, we can start with varient of Reccurrent Neural Network, I have chosen LSTM model.","metadata":{}},{"id":"ea97c1ac-af9e-436a-a12c-a85fa829ac2e","cell_type":"markdown","source":"## Loading Dataset","metadata":{}},{"id":"44ebdcdb","cell_type":"code","source":"# Load dataset\ndf = pd.read_csv(\"/kaggle/input/quora-spam-questions/train.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T08:27:32.416422Z","iopub.execute_input":"2025-06-23T08:27:32.416606Z","iopub.status.idle":"2025-06-23T08:27:34.830608Z","shell.execute_reply.started":"2025-06-23T08:27:32.416593Z","shell.execute_reply":"2025-06-23T08:27:34.830052Z"}},"outputs":[],"execution_count":16},{"id":"5b298c3f","cell_type":"code","source":"# Rename columns\ndf = df.rename(columns={\"question_text\": \"question\", \"target\": \"label\"})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T08:27:34.832254Z","iopub.execute_input":"2025-06-23T08:27:34.832981Z","iopub.status.idle":"2025-06-23T08:27:34.889305Z","shell.execute_reply.started":"2025-06-23T08:27:34.832955Z","shell.execute_reply":"2025-06-23T08:27:34.888797Z"}},"outputs":[],"execution_count":17},{"id":"0b07bb20-9f37-45a9-be61-0c10e66cfa78","cell_type":"code","source":"df['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T09:23:50.560580Z","iopub.execute_input":"2025-06-23T09:23:50.560858Z","iopub.status.idle":"2025-06-23T09:23:50.577662Z","shell.execute_reply.started":"2025-06-23T09:23:50.560838Z","shell.execute_reply":"2025-06-23T09:23:50.576948Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"label\n0    1225312\n1      80810\nName: count, dtype: int64"},"metadata":{}}],"execution_count":28},{"id":"50e639a9-46e0-4303-8610-6bb826362524","cell_type":"markdown","source":"**Data is highly imbalanced hence using Stratified sampling while splitting between train, test, validation sets.**","metadata":{}},{"id":"63db00ae","cell_type":"code","source":"# Split dataset\ntrain_df, test_df = train_test_split(df, test_size=0.1, stratify=df['label'], random_state=42)\ntrain_df, val_df = train_test_split(train_df, test_size=0.1111, stratify=train_df['label'], random_state=42)  # to make 80-10-10 split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T08:27:34.890011Z","iopub.execute_input":"2025-06-23T08:27:34.890270Z","iopub.status.idle":"2025-06-23T08:27:36.740608Z","shell.execute_reply.started":"2025-06-23T08:27:34.890247Z","shell.execute_reply":"2025-06-23T08:27:36.740038Z"}},"outputs":[],"execution_count":18},{"id":"0cad9628-ffc2-413a-8834-6d038fd574be","cell_type":"code","source":"print(train_df['label'].value_counts())\nprint(test_df['label'].value_counts())\nprint(val_df['label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T09:26:45.502008Z","iopub.execute_input":"2025-06-23T09:26:45.502711Z","iopub.status.idle":"2025-06-23T09:26:45.515289Z","shell.execute_reply.started":"2025-06-23T09:26:45.502682Z","shell.execute_reply":"2025-06-23T09:26:45.514494Z"}},"outputs":[{"name":"stdout","text":"label\n0    980260\n1     64649\nName: count, dtype: int64\nlabel\n0    122532\n1      8081\nName: count, dtype: int64\nlabel\n0    122520\n1      8080\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":34},{"id":"b4e9eea7-c44d-46cc-ae31-fc8c1c8f5271","cell_type":"markdown","source":"## Data preperation","metadata":{}},{"id":"1b868076","cell_type":"code","source":"# Build vocab\ndef build_vocab(sentences, min_freq=1):\n    freq = {}\n    for sent in sentences:\n        for word in word_tokenize(sent.lower()):\n            freq[word] = freq.get(word, 0) + 1\n    vocab = {word for word, count in freq.items() if count >= min_freq}\n    word2idx = {word: idx+2 for idx, word in enumerate(vocab)}\n    word2idx['<PAD>'] = 0\n    word2idx['<UNK>'] = 1\n    return word2idx\n\nword2idx = build_vocab(train_df['question'].tolist())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T08:27:36.741206Z","iopub.execute_input":"2025-06-23T08:27:36.741420Z","iopub.status.idle":"2025-06-23T08:28:58.810461Z","shell.execute_reply.started":"2025-06-23T08:27:36.741404Z","shell.execute_reply":"2025-06-23T08:28:58.809810Z"}},"outputs":[],"execution_count":19},{"id":"756a2d21","cell_type":"code","source":"# Load GloVe embeddings\ndef load_glove(path, word2idx, dim=100):\n    embeddings = np.random.uniform(-0.25, 0.25, (len(word2idx), dim))\n    embeddings[word2idx['<PAD>']] = np.zeros(dim)\n    with open(path, 'r', encoding='utf8') as f:\n        for line in f:\n            parts = line.strip().split()\n            word = parts[0]\n            if word in word2idx:\n                embeddings[word2idx[word]] = np.array(parts[1:], dtype=np.float32)\n    return torch.tensor(embeddings, dtype=torch.float32)\n\nglove_path = \"/kaggle/input/quora-spam-questions/glove.6B.100d.txt\"  # Download from https://nlp.stanford.edu/data/glove.6B.zip\nembedding_matrix = load_glove(glove_path, word2idx, dim=100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T08:28:58.811195Z","iopub.execute_input":"2025-06-23T08:28:58.811486Z","iopub.status.idle":"2025-06-23T08:29:03.246304Z","shell.execute_reply.started":"2025-06-23T08:28:58.811461Z","shell.execute_reply":"2025-06-23T08:29:03.245721Z"}},"outputs":[],"execution_count":20},{"id":"08285e10","cell_type":"code","source":"MAX_LEN = 30\n\ndef encode_sentence(sent, word2idx):\n    tokens = word_tokenize(sent.lower())\n    idxs = [word2idx.get(tok, word2idx['<UNK>']) for tok in tokens]\n    if len(idxs) < MAX_LEN:\n        idxs += [word2idx['<PAD>']] * (MAX_LEN - len(idxs))\n    else:\n        idxs = idxs[:MAX_LEN]\n    return idxs\n\nclass QuoraDataset(Dataset):\n    def __init__(self, df, word2idx):\n        self.samples = [(encode_sentence(row['question'], word2idx), row['label']) for _, row in df.iterrows()]\n    def __len__(self):\n        return len(self.samples)\n    def __getitem__(self, idx):\n        x, y = self.samples[idx]\n        return torch.tensor(x).to(device), torch.tensor(y).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T08:29:03.247122Z","iopub.execute_input":"2025-06-23T08:29:03.247411Z","iopub.status.idle":"2025-06-23T08:32:06.043518Z","shell.execute_reply.started":"2025-06-23T08:29:03.247389Z","shell.execute_reply":"2025-06-23T08:32:06.042845Z"}},"outputs":[],"execution_count":21},{"id":"81d8ea10-b696-4bf4-9ddc-04f2b815cc96","cell_type":"code","source":"train_data = QuoraDataset(train_df, word2idx)\nval_data = QuoraDataset(val_df, word2idx)\ntest_data = QuoraDataset(test_df, word2idx)\n\ntrain_loader = DataLoader(train_data, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=32)\ntest_loader = DataLoader(test_data, batch_size=32)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d0be9c2b-fa4a-409b-a508-933598dd01c7","cell_type":"markdown","source":"## Model Configuration","metadata":{}},{"id":"a10ad3c6","cell_type":"code","source":"class LSTMClassifier(nn.Module):\n    def __init__(self, embedding_matrix, hidden_dim=128):\n        super().__init__()\n        num_embeddings, embedding_dim = embedding_matrix.shape\n        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, 1)\n    \n    def forward(self, x):\n        embedded = self.embedding(x)\n        _, (hidden, _) = self.lstm(embedded)\n        out = self.fc(hidden[-1])\n        return torch.sigmoid(out).squeeze(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T08:32:06.044254Z","iopub.execute_input":"2025-06-23T08:32:06.044541Z","iopub.status.idle":"2025-06-23T08:32:06.049944Z","shell.execute_reply.started":"2025-06-23T08:32:06.044519Z","shell.execute_reply":"2025-06-23T08:32:06.049189Z"}},"outputs":[],"execution_count":22},{"id":"f6679a77-544b-4fe2-a9b4-9f5d31bdfb43","cell_type":"markdown","source":"## Training & Validation:","metadata":{}},{"id":"ee3a3175-688e-4a3e-b3e5-c00e3cbed979","cell_type":"code","source":"def train(model, loader, optimizer, criterion):\n    model.train()\n    total_loss = 0\n    for x, y in tqdm(loader):\n        x, y = x.to(device), y.float().to(device)\n        optimizer.zero_grad()\n        output = model(x)\n        loss = criterion(output, y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(loader)\n\ndef evaluate(model, loader):\n    model.eval()\n    preds, labels = [], []\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device)\n            output = model(x)\n            preds.extend((output > 0.5).cpu().numpy())\n            labels.extend(y.cpu().numpy())\n    acc = np.mean(np.array(preds) == np.array(labels))\n    return acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T08:32:06.051693Z","iopub.execute_input":"2025-06-23T08:32:06.051893Z","iopub.status.idle":"2025-06-23T08:32:06.067228Z","shell.execute_reply.started":"2025-06-23T08:32:06.051879Z","shell.execute_reply":"2025-06-23T08:32:06.066561Z"}},"outputs":[],"execution_count":23},{"id":"5f951510-b69a-4bd1-a254-72be38468239","cell_type":"code","source":"def train_validation_loop(model, num_epochs=5, lr=0.001):\n    \n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr)\n\n    best_val_acc = 0.0\n\n    for epoch in range(num_epochs):\n        loss = train(model, train_loader, optimizer, criterion)\n        train_acc = evaluate(model, train_loader)\n        val_acc = evaluate(model, val_loader)\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), \"/kaggle/working/quora_spam_model_best.pth\")\n            print(f\"Best model is saved at {epoch+1}\")\n        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {loss:.4f} | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T08:32:06.067950Z","iopub.execute_input":"2025-06-23T08:32:06.068164Z","iopub.status.idle":"2025-06-23T08:32:06.078202Z","shell.execute_reply.started":"2025-06-23T08:32:06.068142Z","shell.execute_reply":"2025-06-23T08:32:06.077620Z"}},"outputs":[],"execution_count":24},{"id":"634b9de1","cell_type":"code","source":"model = LSTMClassifier(embedding_matrix).to(device)\n\ntrain_validation_loop(model, num_epochs=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T08:32:06.078811Z","iopub.execute_input":"2025-06-23T08:32:06.078999Z","iopub.status.idle":"2025-06-23T09:10:29.272631Z","shell.execute_reply.started":"2025-06-23T08:32:06.078985Z","shell.execute_reply":"2025-06-23T09:10:29.271917Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 32654/32654 [05:59<00:00, 90.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Best model is saved at 1\nEpoch 1/5 - Loss: 0.1132 | Train Acc: 0.96% | Val Acc: 0.96%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 32654/32654 [06:00<00:00, 90.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/5 - Loss: 0.0941 | Train Acc: 0.97% | Val Acc: 0.96%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 32654/32654 [06:00<00:00, 90.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/5 - Loss: 0.0822 | Train Acc: 0.97% | Val Acc: 0.96%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 32654/32654 [06:01<00:00, 90.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/5 - Loss: 0.0718 | Train Acc: 0.98% | Val Acc: 0.95%\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 32654/32654 [06:01<00:00, 90.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/5 - Loss: 0.0624 | Train Acc: 0.98% | Val Acc: 0.95%\n","output_type":"stream"}],"execution_count":25},{"id":"90ed8bde-66e5-4b04-adc4-ecfec49211c2","cell_type":"code","source":"model = LSTMClassifier(embedding_matrix).to(device)\n\n# Load best model\nmodel.load_state_dict(torch.load(\"/kaggle/working/quora_spam_model_best.pth\"))\n\n# Test Accuracy\ntest_acc = evaluate(model, test_loader)\nprint(f\"Test Accuracy: {test_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T09:10:29.273345Z","iopub.execute_input":"2025-06-23T09:10:29.273796Z","iopub.status.idle":"2025-06-23T09:10:40.441790Z","shell.execute_reply.started":"2025-06-23T09:10:29.273777Z","shell.execute_reply":"2025-06-23T09:10:40.441122Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.9585\n","output_type":"stream"}],"execution_count":26},{"id":"35184b4a-3cdc-4be8-8461-fafb2b1c4e67","cell_type":"markdown","source":"## Prediction:","metadata":{}},{"id":"1216bf62","cell_type":"code","source":"# Inference\ndef predict(model, sentence):\n    model.eval()\n    encoded = encode_sentence(sentence, word2idx)\n    tensor = torch.tensor(encoded).unsqueeze(0).to(device)\n    with torch.no_grad():\n        output = model(tensor)\n        return \"Spam\" if output.item() > 0.5 else \"Not Spam\"\n\nprint(predict(model, \"When will Texas finally execute it's last citizen? When they do, who will turn off the lights?\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T09:31:09.123578Z","iopub.execute_input":"2025-06-23T09:31:09.124186Z","iopub.status.idle":"2025-06-23T09:31:09.130807Z","shell.execute_reply.started":"2025-06-23T09:31:09.124165Z","shell.execute_reply":"2025-06-23T09:31:09.130177Z"}},"outputs":[{"name":"stdout","text":"Not Spam\n","output_type":"stream"}],"execution_count":39},{"id":"d04828a7-3111-41df-a4f4-1b87013cf456","cell_type":"markdown","source":"## Observations:\n\n* **With LSTM model, we got 95.85 accuracy on test data set**\n* **One observation is, accuracy is getting decreased on validation dataset as training iterations are getting increased, it seems model is overfitting.**\n* **We can try to tweak the model configuration and experiment if we can increase the model performance on test dataset.**","metadata":{}},{"id":"f7671f1e-4805-4c63-ac1e-ca16ea3eb585","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}